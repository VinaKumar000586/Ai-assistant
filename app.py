import streamlit as st
from langchain.memory import ConversationBufferMemory
from mldl_chatboat import SmartSearch   # Import your SmartSearch class
import time

st.set_page_config(
    page_title="ğŸ“š MindMiner ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ğŸ’¾ Initialize session state
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="history", return_messages=True)

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ğŸŒŸ Sidebar
st.sidebar.title("âš™ï¸ Settings")
st.sidebar.markdown("**AI PDF + Web Assistant**")
st.sidebar.info("Search your PDFs + Web seamlessly with memory context.")
temperature = st.sidebar.slider("Creativity (temperature)", 0.0, 1.0, 0.2)

st.sidebar.markdown("---")
st.sidebar.write("ğŸ’¡ **Tip**: Ask follow-up questions without repeating context!")

# ğŸ¯ Main Header
st.markdown(
    "<h1 style='text-align:center;'>ğŸ“š AI PDF + Web Assistant</h1>",
    unsafe_allow_html=True
)

# ğŸ’¬ Chat Input
user_input = st.chat_input("Ask me something...")

if user_input:
    # Show user message instantly
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # Typing animation
    with st.spinner("ğŸ¤” Thinking..."):
        time.sleep(0.2)  # Small delay for effect
        search_tool = SmartSearch(user_input, st.session_state.memory)
        answer = search_tool.search()

    # Save assistant response
    st.session_state.chat_history.append({"role": "assistant", "content": answer})

# ğŸ–¼ Display Chat
for chat in st.session_state.chat_history:
    if chat["role"] == "user":
        st.markdown(f"ğŸ§‘ **You:** {chat['content']}")
    else:
        st.markdown(f"ğŸ¤– **Assistant:** {chat['content']}")

# ğŸ“Œ Footer
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:gray;'>Built with â¤ï¸ using LangChain, Streamlit & Gemini</div>",
    unsafe_allow_html=True

)
